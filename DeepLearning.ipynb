{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SunwungLee/reproduction/blob/master/DeepLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k-iaK__blQJ",
        "colab_type": "code",
        "outputId": "399da75c-efef-4db2-9c3f-0bb62d5536ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "from tensorflow import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.datasets import cifar10\n",
        "from torch import optim\n",
        "import imgaug.augmenters as iaa\n",
        "from torch import nn\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "SET_MNIST, SET_CIFAR, SET_NORB = 0,1,2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZwpFgisCqwA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def translate(X, x_mag_aug, y_mag_aug):\n",
        "  result = iaa.Affine(translate_px={\"x\": (x_mag_aug, x_mag_aug), \"y\": (y_mag_aug, y_mag_aug)})\n",
        "  seq = iaa.Sequential(result)\n",
        "  images_aug = seq(images=X)\n",
        "  return images_aug\n",
        "\n",
        "def crop(X, mg_aug):\n",
        "  result = iaa.Crop(px=tuple((mg_aug, mg_aug) for i in range(4)),\n",
        "                    sample_independently=True,\n",
        "                    keep_size=True)\n",
        "  seq = iaa.Sequential(result)\n",
        "  images_aug = seq(images=X)\n",
        "  return images_aug\n",
        "\n",
        "def rotate(X, mg_aug):\n",
        "  result = iaa.Affine(rotate=(mg_aug, mg_aug))\n",
        "  seq = iaa.Sequential(result)\n",
        "  images_aug = seq(images=X)\n",
        "  return images_aug"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wujADL25p-qJ",
        "colab": {}
      },
      "source": [
        "def load_dataset(SET_):\n",
        "\tif SET_ == SET_CIFAR:\n",
        "\t\t(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        "\t\tclasses=(0,1)\n",
        "\n",
        "\telif SET_ == SET_MNIST:\n",
        "\t\t(trainX, trainY), (testX, testY) = MNIST.load_data()\n",
        "\t\tclasses=(3,8)\n",
        "\n",
        "\ttrainY = trainY.flatten()\n",
        "\tmask = np.zeros(len(trainY), dtype=np.bool)\n",
        "\tfor c in classes:\n",
        "\t\tmask |= (trainY == c)\n",
        "\t\ttrainX_sub = trainX[mask]\n",
        "\t\ttrainY_sub = trainY\n",
        "\t\ttrainY_sub[mask & (trainY == classes[0])] = 0\n",
        "\t\ttrainY_sub[mask & (trainY == classes[1])] = 1\n",
        "\t\ttrainY_sub = trainY_sub[mask]\n",
        "\n",
        "\ttestY = testY.flatten()\n",
        "\tmask = np.zeros(len(testY), dtype=np.bool)\n",
        "\tfor c in classes:\n",
        "\t\tmask |= (testY == c)\n",
        "\t\ttestX_sub = testX[mask]\n",
        "\t\ttestY_sub = testY\n",
        "\t\ttestY_sub[mask & (testY == classes[0])] = 0\n",
        "\t\ttestY_sub[mask & (testY == classes[1])] = 1\n",
        "\t\ttestY_sub = testY_sub[mask]\n",
        "\t#print(trainY_sub)\n",
        "\ttrainY_sub = to_categorical(trainY_sub)\n",
        "\ttestY_sub = to_categorical(testY_sub)\n",
        "\n",
        "\t#print(trainY_sub)\n",
        "\n",
        "\treturn trainX_sub, trainY_sub, testX_sub, testY_sub\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzHYbFbMCYGi",
        "colab_type": "code",
        "outputId": "be56a697-18a9-44e7-9d18-59c8dafb1aa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "trainX, trainY, testX, testY = load_dataset(SET_CIFAR)\n",
        "\n",
        "f, ax = plt.subplots(1,2)\n",
        "\n",
        "tmp = translate(trainX, 2,2)\n",
        "\n",
        "ax[0].imshow(trainX[0])\n",
        "ax[1].imshow(tmp[0])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7a2e2067f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAC5CAYAAAAxiWT3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4i9GKCoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQhtiOlxswqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from keras.layers import AveragePooling2D, Input, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.datasets import cifar10\n",
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x\n",
        "\n",
        "def resnet_v2(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 2 Model builder [b]\n",
        "\n",
        "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
        "    bottleneck layer\n",
        "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
        "    Second and onwards shortcut connection is identity.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filter maps is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same filter map sizes.\n",
        "    Features maps sizes:\n",
        "    conv1  : 32x32,  16\n",
        "    stage 0: 32x32,  64\n",
        "    stage 1: 16x16, 128\n",
        "    stage 2:  8x8,  256\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
        "    # Start model definition.\n",
        "    num_filters_in = 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # Instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                if res_block == 0:  # first layer and first stage\n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                if res_block == 0:  # first layer but not first stage\n",
        "                    strides = 2    # downsample\n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT0sOYVLtAAu",
        "colab_type": "code",
        "outputId": "d9dd6ee4-3065-47e5-992a-d725c0cd3052",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "\n",
        "if learn_model == 1:\n",
        "  input_shape = trainX.shape[1:]\n",
        "  print(input_shape)\n",
        "  model = None\n",
        "  model = resnet_v2(input_shape, 56, 2)\n",
        "  print(trainY.shape)\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                    optimizer='adam',\n",
        "                    metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  model.fit(trainX, trainY, validation_data=(testX, testY)) # original paper 128\n",
        "  scores = model.evaluate(testX, testY)\n",
        "  print('Test loss; ', scores[0])\n",
        "  print('Test accuracy; ', scores[1])\n",
        "\n",
        "  model.save('model.h5')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 32, 3)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "(10000, 2)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 16)   448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 16)   272         activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 64)   1088        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 64)   1088        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 64)   0           conv2d_5[0][0]                   \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 64)   256         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 64)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 16)   1040        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 16)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 16)   2320        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 16)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 64)   1088        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 64)   0           add_1[0][0]                      \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 64)   256         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 16)   1040        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 16)   2320        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 16)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 64)   1088        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 32, 32, 64)   0           add_2[0][0]                      \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 64)   256         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 32, 32, 64)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 32, 16)   1040        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 16)   64          conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 32, 32, 16)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 32, 16)   2320        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 16)   64          conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 32, 16)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 32, 32, 64)   1088        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 32, 32, 64)   0           add_3[0][0]                      \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 32, 32, 64)   256         add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 32, 32, 64)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 32, 32, 16)   1040        activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 32, 32, 16)   64          conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 32, 32, 16)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 32, 32, 16)   2320        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 32, 32, 16)   64          conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 32, 32, 16)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 32, 32, 64)   1088        activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 32, 32, 64)   0           add_4[0][0]                      \n",
            "                                                                 conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 32, 32, 64)   256         add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 32, 32, 64)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 32, 32, 16)   1040        activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 32, 32, 16)   64          conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 32, 32, 16)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 32, 32, 16)   2320        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 32, 32, 16)   64          conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 32, 32, 16)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 32, 32, 64)   1088        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 32, 32, 64)   0           add_5[0][0]                      \n",
            "                                                                 conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 32, 32, 64)   256         add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 32, 32, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   4160        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 64)   256         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 64)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   36928       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   256         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 128)  8320        add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 128)  8320        activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 16, 16, 128)  0           conv2d_24[0][0]                  \n",
            "                                                                 conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 128)  512         add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 128)  0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   8256        activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 64)   256         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 64)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 16, 16, 64)   36928       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 64)   256         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 64)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 128)  8320        activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 16, 16, 128)  0           add_7[0][0]                      \n",
            "                                                                 conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 128)  512         add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 128)  0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 64)   8256        activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 16, 16, 64)   256         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 16, 16, 64)   0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 16, 16, 64)   36928       activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   256         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 16, 16, 128)  8320        activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 16, 16, 128)  0           add_8[0][0]                      \n",
            "                                                                 conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 128)  512         add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 128)  0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 16, 16, 64)   8256        activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 16, 16, 64)   256         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 16, 16, 64)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 16, 16, 64)   36928       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 16, 16, 64)   256         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 16, 16, 64)   0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 16, 16, 128)  8320        activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 16, 16, 128)  0           add_9[0][0]                      \n",
            "                                                                 conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 16, 16, 128)  512         add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 16, 16, 128)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 16, 16, 64)   8256        activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 16, 16, 64)   256         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 16, 16, 64)   0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 16, 16, 64)   36928       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 16, 16, 64)   256         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 16, 16, 64)   0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 16, 16, 128)  8320        activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 16, 16, 128)  0           add_10[0][0]                     \n",
            "                                                                 conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 16, 16, 128)  512         add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 16, 16, 128)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 16, 16, 64)   8256        activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 16, 16, 64)   256         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 16, 16, 64)   0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 16, 16, 64)   36928       activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 16, 16, 64)   256         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 16, 16, 64)   0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 16, 16, 128)  8320        activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 16, 16, 128)  0           add_11[0][0]                     \n",
            "                                                                 conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 16, 16, 128)  512         add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 16, 16, 128)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 8, 8, 128)    16512       activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 8, 8, 128)    512         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 8, 8, 128)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 8, 8, 128)    147584      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 8, 8, 128)    512         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 8, 8, 128)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 8, 8, 256)    33024       add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 8, 8, 256)    33024       activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 8, 8, 256)    0           conv2d_43[0][0]                  \n",
            "                                                                 conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 8, 8, 256)    1024        add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 8, 8, 256)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 8, 8, 128)    32896       activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 8, 8, 128)    512         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 8, 8, 128)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 8, 8, 128)    147584      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 8, 8, 128)    512         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 8, 8, 128)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 8, 8, 256)    33024       activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 8, 8, 256)    0           add_13[0][0]                     \n",
            "                                                                 conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 8, 8, 256)    1024        add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 8, 8, 256)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 8, 8, 128)    32896       activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 8, 8, 128)    512         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 8, 8, 128)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 8, 8, 128)    147584      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 8, 8, 128)    512         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 8, 8, 128)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 8, 8, 256)    33024       activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 8, 8, 256)    0           add_14[0][0]                     \n",
            "                                                                 conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 8, 8, 256)    1024        add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 8, 8, 256)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 8, 8, 128)    32896       activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 8, 8, 128)    512         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 8, 8, 128)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 8, 8, 128)    147584      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 8, 8, 128)    512         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 8, 8, 128)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 8, 8, 256)    33024       activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, 8, 8, 256)    0           add_15[0][0]                     \n",
            "                                                                 conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 8, 8, 256)    1024        add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 8, 8, 256)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 8, 8, 128)    32896       activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 8, 8, 128)    512         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 8, 8, 128)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 8, 8, 128)    147584      activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 8, 8, 128)    512         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 8, 8, 128)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 8, 8, 256)    33024       activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 8, 8, 256)    0           add_16[0][0]                     \n",
            "                                                                 conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 8, 8, 256)    1024        add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 8, 8, 256)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 8, 8, 128)    32896       activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 8, 8, 128)    512         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 8, 8, 128)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 8, 8, 128)    147584      activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 8, 8, 128)    512         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 8, 8, 128)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 8, 8, 256)    33024       activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 8, 8, 256)    0           add_17[0][0]                     \n",
            "                                                                 conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 8, 8, 256)    1024        add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 8, 8, 256)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 1, 1, 256)    0           activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 256)          0           average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 2)            514         flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,671,682\n",
            "Trainable params: 1,661,282\n",
            "Non-trainable params: 10,400\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 10000 samples, validate on 2000 samples\n",
            "Epoch 1/1\n",
            "10000/10000 [==============================] - 709s 71ms/step - loss: 1.1982 - acc: 0.8560 - val_loss: 1.0212 - val_acc: 0.8325\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7a261d2550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA4uBcLwwCsp",
        "colab_type": "code",
        "outputId": "6ea81b7d-1971-40bc-df3c-acfa719310f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000/2000 [==============================] - 47s 23ms/step\n",
            "Test loss;  1.0212062225341796\n",
            "Test accuracy;  0.8325\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsR-WHcX_aW7",
        "colab_type": "code",
        "outputId": "14777b5a-25fe-4969-ea7a-dc73fa64d6e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import sklearn \n",
        "import sklearn.linear_model\n",
        "import sklearn.pipeline\n",
        "\n",
        "clf = sklearn.linear_model.LogisticRegression(max_iter=1000)\n",
        "newmodel = Model(model.inputs, model.layers[-2].output)\n",
        "print(\"pass2\")\n",
        "clf.fit(newmodel.predict(trainX), trainY.argmax(1))\n",
        "print(\"pass\")\n",
        "print(clf.score(newmodel.predict(testX), testY.argmax(1)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pass2\n",
            "pass\n",
            "0.929\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0vZLng0KeH_",
        "colab_type": "code",
        "outputId": "0f395464-9854-4bce-b8ee-4a0e4745b1f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import math\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + math.exp(-x))\n",
        "\n",
        "loss = np.zeros(trainX.shape[0])\n",
        "print('#: ', trainX.shape[0])\n",
        "\n",
        "for i in range(trainX.shape[0]):\n",
        "  y = trainY.argmax(1)[i] \n",
        "  s = sigmoid(np.dot(newmodel.predict(trainX[i:i+1]), clf.coef_.T))\n",
        "  loss[i] = -1 * (y*math.log(s)) + (1-y)*math.log(1-s)\n",
        "  #loss[i] = (sigmoid(np.dot(newmodel.predict(trainX[i:i+1]), clf.coef_.T)) - trainY.argmax(1)[i]) ** 2\n",
        "\n",
        "print(loss.shape)\n",
        "print(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#:  10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3fFUNl7PL7U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "b6baaea5-d382-4320-8bf2-6128c561cd6e"
      },
      "source": [
        "#print(sigmoid(np.dot(newmodel.predict(trainX[i:i+1]), clf.coef_.T)).shape)\n",
        "#print(newmodel.predict(trainX[:1]).shape)\n",
        "print(trainY.argmax(1).shape)\n",
        "print(loss)\n",
        "print(clf.coef_.T.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000,)\n",
            "[1.06639673e-06 1.11245269e-08 1.53965168e-01 ... 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00]\n",
            "(256, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzrDO6tvDYOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "x = newmodel.predict(trainX)\n",
        "n = x.shape\n",
        "hess = np.dot(x.T,x)\n",
        "for i in range(n):\n",
        "  \n",
        "  pred = np.dot(x[i], clf.coef_.T)\n",
        "  y = trainY.argmax(1)[i]\n",
        "\n",
        "  \n",
        "  gradient = np.dot(x.T, (pred-y))\n",
        "  influence[i] = np.dot(np.dot(gradient.T, np.linalg.inv(hess)), gradient)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02IzBI6pNalt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = x.shape[0]\n",
        "hess = np.dot(x.T,x)\n",
        "\n",
        "influence = np.zeros(n)\n",
        "for i in range(n):  \n",
        "  rx = x[i].reshape(256,-1)\n",
        "  pred = np.dot(rx, clf.coef_)\n",
        "  y = trainY.argmax(1)[i]\n",
        " \n",
        "  gradient = np.dot(rx.T, (pred-y))\n",
        "  influence[i] = np.dot(np.dot(gradient, np.linalg.inv(hess)), gradient.T)\n",
        "\n",
        "print('x', x.shape) # 10,000 x 256\n",
        "print('hess',hess.shape) # 256 x 256\n",
        "print('grad',gradient.shape) # 256 x 10,000\n",
        "print('pred',pred.shape) # 10,000 x 1\n",
        "print('pred-y',(pred-y).shape) # 10,000 x 1\n",
        "\n",
        "print(influence.shape)\n",
        "print(influence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmLP-Gi7ZfQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot\n",
        "matplotlib.pyplot.hist(influence, bins=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1r19KHaqe8ou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}